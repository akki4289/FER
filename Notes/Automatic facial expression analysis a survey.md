#Automatic facial expression analysis: a survey

##Abstract
Over the last decade, automatic facial expression analysis has become an active research area that finds potential applications in areas such as more engaging humanâ€“computer interfaces, talking heads, image retrieval and human emotion analysis. Facial expressions reflect not only emotions, but other mental activities, social interaction and physiological signals. In this survey, we introduce the most prominent automatic facial expression analysis methods and systems presented in the literature. Facial motion and deformation extraction approaches as well as classification methods are discussed with respect to issues such as face normalization, facial expression dynamics and facial expression intensity, but also with regard to their robustness towards environmental changes.

##Introduction

Facial expression analysis goes back into the 19th century.

Six primary emotions where introduced in 1971, by Ekman and Friesen. Each of these emotions have a unique facial expression. They are called the basic emotions.
They are *happiness*, *sadness*, *fear*, *disgust*, *surprise* and *anger*.

Automatic facial expression analysis from an image sequence, was started in 1978 by Suwa.

###Difference between **Facial expression recognition** and **Human emotion recognition**

While facial expression recognition deals with the classi0cation of facial motion and facial feature deformation into abstract classes that are purely based on visual information, human emotions are a result of many di7erent factors and their state might or might not be revealed through a number ofchannels such as emotional voice, pose, gestures, gaze direction and facial expressions.

Facial expressions have many sources: mental state, non-verbal communication, physiological activities and verbal communication.

##facial expression measurment

Facial expressions are generated by facial muscles.
Typical changes of muscular activities are brief, lasting between 5 s to 25 ms.

We can measure _location_, _intensity_ and _dynamics_ of a facial actions.

Since there are inter-personal variations with regard to the amplitudes off acial actions, it is difficult to determine absolute facial expression intensities, without referring to the neutral face of a given subject.

Facial expressions can be described with the aid of three temporal parameters: _onset_ (attack), _apex_ (sustain), _offset_ (relaxation).

There are two main methodological approaches of how to measure the three characteristics of facial expressions:

* _message judgment_-based approaches: directly associate specific facial patters with mental activities
* _sign vehicle_-based approaches: represent facial actions in a coded way, prior to eventual interpretation attempts.

