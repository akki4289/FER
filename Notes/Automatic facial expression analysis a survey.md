#Automatic facial expression analysis: a survey

##Abstract
Over the last decade, automatic facial expression analysis has become an active research area that finds potential applications in areas such as more engaging humanâ€“computer interfaces, talking heads, image retrieval and human emotion analysis. Facial expressions reflect not only emotions, but other mental activities, social interaction and physiological signals. In this survey, we introduce the most prominent automatic facial expression analysis methods and systems presented in the literature. Facial motion and deformation extraction approaches as well as classification methods are discussed with respect to issues such as face normalization, facial expression dynamics and facial expression intensity, but also with regard to their robustness towards environmental changes.

##Introduction

Facial expression analysis goes back into the 19th century.

Six primary emotions where introduced in 1971, by Ekman and Friesen. Each of these emotions have a unique facial expression. They are called the basic emotions.
They are *happiness*, *sadness*, *fear*, *disgust*, *surprise* and *anger*.

Automatic facial expression analysis from an image sequence, was started in 1978 by Suwa.

###Difference between **Facial expression recognition** and **Human emotion recognition**

While facial expression recognition deals with the classi0cation of facial motion and facial feature deformation into abstract classes that are purely based on visual information, human emotions are a result of many di7erent factors and their state might or might not be revealed through a number ofchannels such as emotional voice, pose, gestures, gaze direction and facial expressions.

Facial expressions have many sources: mental state, non-verbal communication, physiological activities and verbal communication.

##facial expression measurment

Facial expressions are generated by facial muscles.
Typical changes of muscular activities are brief, lasting between 5 s to 25 ms.

We can measure _location_, _intensity_ and _dynamics_ of a facial actions.

Since there are inter-personal variations with regard to the amplitudes off acial actions, it is difficult to determine absolute facial expression intensities, without referring to the neutral face of a given subject.

Facial expressions can be described with the aid of three temporal parameters: _onset_ (attack), _apex_ (sustain), _offset_ (relaxation).

There are two main methodological approaches of how to measure the three characteristics of facial expressions:

* _message judgment_-based approaches: directly associate specific facial patters with mental activities
* _sign vehicle_-based approaches: represent facial actions in a coded way, prior to eventual interpretation attempts.

###Judgment-based approaches

Most automatic facial expression analysis approaches attemp to directly map facial expressions into one of the 6 basic emotion classes.

###Sign-based appraches

?

##Reliability of ground truth coding

?

#Automatic facial expression analysis

##Face acquisition

* Includes an automatic face detector.
There are two main types of facial analysis methods: the ones which need the exact posotion of the face, and the ones which work with coarse location of the face.

It is always a good idea to normalize faces prior to their analysis:
  * _Pose_: the angle and distance at which a given face is being observed.
  Pose variations occur due to *scale changes* as well as *in-plane* and *out-of-plane* rotation of faces.
  obviously the out-of-plane rotation is the hard one to fix.

  * _Illumination_: Common approach: filter the image with Gabor wavelets.
  There are problems with partly lighted faces. This is solved for face recognition by Belhumeur, but not yet sufficiently for facial expression analysis.

As long as extracted feature parameters are normalized prior to their classifivation, _face normalization_ is _not mandatory_. Appearance-based model and local motion model approaches have dealt with significant out-of-plane rotations without relying on face normalization.

##Feature extraction and representation

