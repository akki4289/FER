#Papers I've read:

##Automatic facial expression analysis: a survey

* B. Fasel, Juergen Luettin
* Cited by 664
* Pattern Recognition, 2003
* Elsevier
* [http://www.sciencedirect.com/science/article/pii/S0031320302000523](link)

###Abstract
Over the last decade, automatic facial expression analysis has become an active research area that finds potential applications in areas such as more engaging humanâ€“computer interfaces, talking heads, image retrieval and human emotion analysis. Facial expressions reflect not only emotions, but other mental activities, social interaction and physiological signals. In this survey, we introduce the most prominent automatic facial expression analysis methods and systems presented in the literature. Facial motion and deformation extraction approaches as well as classification methods are discussed with respect to issues such as face normalization, facial expression dynamics and facial expression intensity, but also with regard to their robustness towards environmental changes.

##Coding, analysis, interpretation, and recognition of facial expressions

* Essa I.A., Pentland A.P.
* Cited by 630
* Analysis and Machine Intelligence, 1997
* ieee
* [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=598232&tag=1](link)

###Abstract
We describe a computer vision system for observing facial motion by using an optimal estimation optical flow method coupled with geometric, physical and motion-based dynamic models describing the facial structure. Our method produces a reliable parametric representation of the face's independent muscle action groups, as well as an accurate estimate of facial motion. Previous efforts at analysis of facial expression have been based on the facial action coding system (FACS), a representation developed in order to allow human psychologists to code expression from static pictures. To avoid use of this heuristic coding scheme, we have used our computer vision system to probabilistically characterize facial motion and muscle activation in an experimental population, thus deriving a new, more accurate, representation of human facial expressions that we call FACS+. Finally, we show how this method can be used for coding, analysis, interpretation, and recognition of facial expressions

##Comprehensive database for facial expression analysis

* Kanade, T.;   Cohn, J.F.;   Yingli Tian;   
* Cited by 876
* Automatic Face and Gesture Recognition, 2000
* ieee
* [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=840611](link)

###Abstract
Within the past decade, significant effort has occurred in developing methods of facial expression analysis. Because most investigators have used relatively limited data sets, the generalizability of these various methods remains unknown. We describe the problem space for facial expression analysis, which includes level of description, transitions among expressions, eliciting conditions, reliability and validity of training and test data, individual differences in subjects, head orientation and scene complexity image characteristics, and relation to non-verbal behavior. We then present the CMU-Pittsburgh AU-Coded Face Expression Image Database, which currently includes 2105 digitized image sequences from 182 adult subjects of varying ethnicity, performing multiple tokens of most primary FACS action units. This database is the most comprehensive testbed to date for comparative studies of facial expression analysis

##Facial expression recognition using a dynamic model and motion energy

* I.A. Essa, A.P. Pentland
* Cited by 233
* Computer Vision, 1995. Proceedings., Fifth International Conference on
* ieee
* [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=466916](link)

###Abstract
Previous efforts at facial expression recognition have been based on the Facial Action Coding System (FACS), a representation developed in order to allow human psychologists to code expression from static facial "mugshots." We develop new more accurate representations for facial expression by building a video database of facial expressions and then probabilistically characterizing the facial muscle activation associated with each expression using a detailed physical model of the skin and muscles. This produces a muscle based representation of facial motion, which is then used to recognize facial expressions in two different ways. The first method uses the physics based model directly, by recognizing expressions through comparison of estimated muscle activations. The second method uses the physics based model to generate spatio temporal motion energy templates of the whole face for each different expression. These simple, biologically plausible motion energy "templates" are then used for recognition. Both methods show substantially greater accuracy at expression recognition than has been previously achieved.

